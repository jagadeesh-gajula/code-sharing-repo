{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "communist-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "voluntary-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.Series((1,2,3,5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "yellow-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    5\n",
       "4    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "about-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>hi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>hello</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          one  two  three  four  five\n",
       "first      hi  2.0    3.6     4     5\n",
       "second  hello  2.0    3.0     4     5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame([[\"hi\",2.0,3.6,4,5],[\"hello\",2,3,4,5]],columns = [\"one\",\"two\",\"three\",\"four\",\"five\"],index = [\"first\",\"second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "located-bidder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_excel in module pandas.io.excel._base:\n",
      "\n",
      "read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
      "    Read an Excel file into a pandas DataFrame.\n",
      "    \n",
      "    Supports `xls`, `xlsx`, `xlsm`, `xlsb`, and `odf` file extensions\n",
      "    read from a local filesystem or URL. Supports an option to read\n",
      "    a single sheet or a list of sheets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be: ``file://localhost/path/to/table.xlsx``.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method,\n",
      "        such as a file handler (e.g. via builtin ``open`` function)\n",
      "        or ``StringIO``.\n",
      "    sheet_name : str, int, list, or None, default 0\n",
      "        Strings are used for sheet names. Integers are used in zero-indexed\n",
      "        sheet positions. Lists of strings/integers are used to request\n",
      "        multiple sheets. Specify None to get all sheets.\n",
      "    \n",
      "        Available cases:\n",
      "    \n",
      "        * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
      "        * ``1``: 2nd sheet as a `DataFrame`\n",
      "        * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
      "        * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
      "          as a dict of `DataFrame`\n",
      "        * None: All sheets.\n",
      "    \n",
      "    header : int, list of int, default 0\n",
      "        Row (0-indexed) to use for the column labels of the parsed\n",
      "        DataFrame. If a list of integers is passed those row positions will\n",
      "        be combined into a ``MultiIndex``. Use None if there is no header.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row,\n",
      "        then you should explicitly pass header=None.\n",
      "    index_col : int, list of int, default None\n",
      "        Column (0-indexed) to use as the row labels of the DataFrame.\n",
      "        Pass None if there is no such column.  If a list is passed,\n",
      "        those columns will be combined into a ``MultiIndex``.  If a\n",
      "        subset of data is selected with ``usecols``, index_col\n",
      "        is based on the subset.\n",
      "    usecols : int, str, list-like, or callable default None\n",
      "        * If None, then parse all columns.\n",
      "        * If str, then indicates comma separated list of Excel column letters\n",
      "          and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
      "          both sides.\n",
      "        * If list of int, then indicates list of column numbers to be parsed.\n",
      "        * If list of string, then indicates list of column names to be parsed.\n",
      "    \n",
      "          .. versionadded:: 0.24.0\n",
      "    \n",
      "        * If callable, then evaluate each column name against it and parse the\n",
      "          column if the callable returns ``True``.\n",
      "    \n",
      "        Returns a subset of the columns according to behavior above.\n",
      "    \n",
      "          .. versionadded:: 0.24.0\n",
      "    \n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : str, default None\n",
      "        If io is not a buffer or path, this must be set to identify io.\n",
      "        Acceptable values are None, \"xlrd\", \"openpyxl\" or \"odf\".\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can\n",
      "        either be integers or column labels, values are functions that take one\n",
      "        input argument, the Excel cell content, and return the transformed\n",
      "        content.\n",
      "    true_values : list, default None\n",
      "        Values to consider as True.\n",
      "    false_values : list, default None\n",
      "        Values to consider as False.\n",
      "    skiprows : list-like\n",
      "        Rows to skip at the beginning (0-indexed).\n",
      "    nrows : int, default None\n",
      "        Number of rows to parse.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values. By default the following values are interpreted\n",
      "        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    parse_dates : bool, list-like, or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * bool. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index contains an unparseable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. If you don`t want to\n",
      "        parse some cells as date just change their type in Excel to \"Text\".\n",
      "        For non-standard datetime parsing, use ``pd.to_datetime`` after ``pd.read_excel``.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    thousands : str, default None\n",
      "        Thousands separator for parsing string columns to numeric.  Note that\n",
      "        this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.\n",
      "    comment : str, default None\n",
      "        Comments out remainder of line. Pass a character or characters to this\n",
      "        argument to indicate comments in the input file. Any data between the\n",
      "        comment string and the end of the current line is ignored.\n",
      "    skipfooter : int, default 0\n",
      "        Rows at the end to skip (0-indexed).\n",
      "    convert_float : bool, default True\n",
      "        Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
      "        data will be read in as floats: Excel stores all numbers as floats\n",
      "        internally.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    **kwds : optional\n",
      "            Optional keyword arguments can be passed to ``TextFileReader``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or dict of DataFrames\n",
      "        DataFrame from the passed in Excel file. See notes in sheet_name\n",
      "        argument for more information on when a dict of DataFrames is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The file can be read using the file name as string or an open file object:\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1      1\n",
      "    1   string2      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    >>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
      "    ...               sheet_name='Sheet3')  # doctest: +SKIP\n",
      "       Unnamed: 0      Name  Value\n",
      "    0           0   string1      1\n",
      "    1           1   string2      2\n",
      "    2           2  #Comment      3\n",
      "    \n",
      "    Index and header can be specified via the `index_col` and `header` arguments\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
      "         0         1      2\n",
      "    0  NaN      Name  Value\n",
      "    1  0.0   string1      1\n",
      "    2  1.0   string2      2\n",
      "    3  2.0  #Comment      3\n",
      "    \n",
      "    Column types are inferred but can be explicitly specified\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1    1.0\n",
      "    1   string2    2.0\n",
      "    2  #Comment    3.0\n",
      "    \n",
      "    True, False, and NA values, and thousands separators have defaults,\n",
      "    but can be explicitly specified, too. Supply the values you would like\n",
      "    as strings or lists of strings!\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0       NaN      1\n",
      "    1       NaN      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
      "          Name  Value\n",
      "    0  string1    1.0\n",
      "    1  string2    2.0\n",
      "    2     None    NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pandas.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "three-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
